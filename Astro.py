import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import requests
from datetime import datetime, timedelta
import time

# Seitenkonfiguration
st.set_page_config(
    page_title="Astrotourismus Weltkarte - Live Daten",
    page_icon="üåü",
    layout="wide"
)

# API-Funktionen f√ºr echte Daten
class ClearNightsAPI:
    """
    Klasse f√ºr API-Calls zu Wetter- und Klimadaten
    """
    
    @staticmethod
    @st.cache_data(ttl=24*3600)  # Cache f√ºr 24 Stunden
    def get_nasa_power_data(lat, lon, location_name):
        """
        NASA POWER API f√ºr klimatologische Daten (kostenlos)
        """
        base_url = "https://power.larc.nasa.gov/api/temporal/climatology/point"
        
        params = {
            'parameters': 'CLOUD_AMT_DAY,CLOUD_AMT_NIGHT,RH2M',
            'community': 'RE',
            'longitude': lon,
            'latitude': lat,
            'start': 2010,  # 10 Jahre Durchschnitt
            'end': 2020,
            'format': 'JSON'
        }
        
        try:
            with st.spinner(f'üì° Lade NASA-Daten f√ºr {location_name}...'):
                response = requests.get(base_url, params=params, timeout=10)
                
                if response.status_code == 200:
                    data = response.json()
                    
                    if 'properties' in data and 'parameter' in data['properties']:
                        params_data = data['properties']['parameter']
                        
                        # Nachtbew√∂lkung analysieren
                        cloud_night = params_data.get('CLOUD_AMT_NIGHT', {})
                        humidity = params_data.get('RH2M', {})
                        
                        if cloud_night:
                            # Jahresweite Bew√∂lkungsdaten
                            monthly_clouds = list(cloud_night.values())
                            avg_cloud_cover = sum(monthly_clouds) / len(monthly_clouds)
                            
                            # Berechnung klarer N√§chte
                            # < 30% Bew√∂lkung = klare Nacht f√ºr Astronomie
                            clear_night_probability = max(0, (70 - avg_cloud_cover) / 70)
                            estimated_clear_nights = int(365 * clear_night_probability)
                            
                            # Luftfeuchtigkeit
                            avg_humidity = sum(humidity.values()) / len(humidity) if humidity else 50
                            
                            return {
                                'success': True,
                                'clear_nights': max(estimated_clear_nights, 50),  # Minimum 50
                                'cloud_cover': round(avg_cloud_cover, 1),
                                'humidity': round(avg_humidity, 1),
                                'data_source': 'NASA POWER API',
                                'status': '‚úÖ Live Daten'
                            }
                
        except Exception as e:
            st.warning(f"‚ö†Ô∏è NASA API Fehler f√ºr {location_name}: {str(e)}")
        
        return {'success': False}
    
    @staticmethod
    def get_geographic_estimation(lat, lon, altitude):
        """
        Geografische Sch√§tzung als Fallback
        """
        abs_lat = abs(lat)
        
        # Basis nach Klimazonen
        if altitude > 3000:
            base_clear = 290  # Hochgebirge
        elif abs_lat < 30 and altitude < 500:
            base_clear = 200  # Tropen, niedrig
        elif abs_lat < 30 and altitude > 500:
            base_clear = 280  # Subtropische Hochlagen
        elif 30 <= abs_lat <= 50:
            base_clear = 180  # Gem√§√üigte Zone
        elif abs_lat > 50:
            base_clear = 140  # Polare Regionen
        else:
            base_clear = 200
        
        # Modifikationen
        if altitude > 2000:
            base_clear += 30
        if altitude > 1000:
            base_clear += 15
        
        # Kontinentalit√§t (Abstand zur K√ºste, grobe Sch√§tzung)
        if abs(lon) > 100:  # Kontinentales Klima
            base_clear += 20
            
        return min(max(base_clear, 100), 350)

# Daten mit API-Integration laden
@st.cache_data(ttl=12*3600)  # Cache f√ºr 12 Stunden
def load_enhanced_data():
    """
    Lade Daten mit API-Integration und Fallback
    """
    
    # Basis-Daten (deine urspr√ºnglichen Daten als Fallback)
    base_data = {
        'Name': [
            'Atacama-W√ºste', 'Elqui Valley', 'La Silla Observatory', 'Paranal Observatory',
            'Mauna Kea', 'Death Valley', 'Big Bend', 'Cherry Springs', 'Bryce Canyon',
            'Great Basin NP', 'Capitol Reef NP', 'Arches NP',
            'Jasper Nationalpark', 'Mont-M√©gantic', 'Algonquin Provincial Park',
            'La Palma', 'Pic du Midi', 'Alqueva', 'Brecon Beacons',
            'Aoraki Mackenzie', 'Great Barrier Island', 'Uluru', 'Flinders Ranges',
            'Namibrand', 'Sahara Marokko', 'Kalahari',
            'Ladakh', 'Spiti Valley', 'Gobi-W√ºste'
        ],
        'Land': [
            'Chile', 'Chile', 'Chile', 'Chile',
            'USA (Hawaii)', 'USA', 'USA', 'USA', 'USA',
            'USA', 'USA', 'USA',
            'Kanada', 'Kanada', 'Kanada',
            'Spanien', 'Frankreich', 'Portugal', 'Wales',
            'Neuseeland', 'Neuseeland', 'Australien', 'Australien',
            'Namibia', 'Marokko', 'Botswana',
            'Indien', 'Indien', 'Mongolei'
        ],
        'Latitude': [
            -24.6282, -29.9081, -29.2563, -24.6275,
            19.8207, 36.5054, 29.1275, 41.6628, 37.5930,
            39.2856, 38.2972, 38.7331,
            52.8737, 45.4532, 45.5017,
            28.7636, 42.9369, 38.2433, 51.8838,
            -44.0061, -36.1833, -25.3444, -32.1283,
            -25.0000, 31.7917, -22.0000,
            34.1526, 32.2432, 43.0000
        ],
        'Longitude': [
            -70.4034, -70.8217, -70.7369, -70.4033,
            -155.4681, -117.0794, -103.2420, -77.8261, -112.1660,
            -114.2669, -111.2615, -109.5925,
            -117.9542, -71.1513, -78.3947,
            -17.8735, 0.1426, -7.5000, -3.4360,
            170.1409, 175.0833, 131.0369, 138.6283,
            16.0000, -7.0926, 24.0000,
            77.5771, 78.0647, 103.0000
        ],
        'H√∂he_m': [
            2400, 1500, 2400, 2635,
            4200, 1669, 1200, 670, 2400,
            2000, 1800, 1500,
            1200, 1114, 400,
            2396, 2877, 152, 520,
            1031, 200, 348, 800,
            1200, 1165, 1000,
            3500, 4000, 1500
        ],
        'Bortle_Skala': [
            1, 1, 1, 1,
            1, 1, 1, 2, 2,
            1, 2, 2,
            2, 2, 3,
            2, 2, 2, 3,
            1, 2, 1, 1,
            1, 1, 1,
            1, 1, 1
        ],
        'Typ': [
            'W√ºste', 'W√ºste', 'Observatorium', 'Observatorium',
            'Observatorium', 'Dark Sky Park', 'Dark Sky Park', 'Dark Sky Park', 'Dark Sky Park',
            'Dark Sky Park', 'Dark Sky Park', 'Dark Sky Park',
            'Dark Sky Preserve', 'Dark Sky Reserve', 'Dark Sky Preserve',
            'Observatorium', 'Observatorium', 'Dark Sky Reserve', 'Dark Sky Reserve',
            'Dark Sky Reserve', 'Dark Sky Sanctuary', 'Dark Sky Sanctuary', 'Dark Sky Reserve',
            'Dark Sky Reserve', 'W√ºste', 'W√ºste',
            'Hochgebirge', 'Hochgebirge', 'W√ºste'
        ],
        # Fallback-Werte f√ºr klare N√§chte
        'Fallback_Klare_N√§chte': [
            320, 330, 310, 325,
            300, 350, 320, 200, 220,
            280, 250, 240,
            200, 180, 160,
            280, 220, 260, 180,
            250, 200, 290, 270,
            310, 300, 280,
            280, 270, 240
        ]
    }
    
    df = pd.DataFrame(base_data)
    
    # API-Integration
    api = ClearNightsAPI()
    enhanced_data = []
    
    # Progress bar f√ºr API-Calls
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for idx, row in df.iterrows():
        progress = (idx + 1) / len(df)
        progress_bar.progress(progress)
        status_text.text(f'üì° Lade Daten f√ºr {row["Name"]} ({idx+1}/{len(df)})')
        
        # NASA API Call
        api_result = api.get_nasa_power_data(
            row['Latitude'], 
            row['Longitude'], 
            row['Name']
        )
        
        if api_result['success']:
            # API-Daten verf√ºgbar
            clear_nights = api_result['clear_nights']
            humidity = api_result['humidity']
            data_source = api_result['data_source']
            status = api_result['status']
        else:
            # Fallback zu geografischer Sch√§tzung
            clear_nights = api.get_geographic_estimation(
                row['Latitude'], 
                row['Longitude'], 
                row['H√∂he_m']
            )
            humidity = 50  # Standardwert
            data_source = 'Geographic Estimation'
            status = 'üîÑ Sch√§tzung'
        
        # Temperatur-Sch√§tzung basierend auf H√∂he und Breite
        temperature = 20 - (row['H√∂he_m'] / 150) - (abs(row['Latitude']) / 3)
        
        enhanced_row = {
            **row.to_dict(),
            'Klare_N√§chte_Jahr': clear_nights,
            'Luftfeuchtigkeit_%': humidity,
            'Temperatur_¬∞C': round(temperature, 1),
            'Datenquelle': data_source,
            'Status': status
        }
        
        enhanced_data.append(enhanced_row)
        
        # Kleine Pause um API nicht zu √ºberlasten
        time.sleep(0.1)
    
    progress_bar.empty()
    status_text.empty()
    
    return pd.DataFrame(enhanced_data)

# Titel und Beschreibung
st.title("üåü Weltkarte f√ºr Astrotourismus - Live Daten Edition")
st.markdown("""
Diese interaktive Karte zeigt die besten Orte weltweit f√ºr Sternenbeobachtung und Astrotourismus
mit **echten Wetterdaten** von NASA POWER API und geografischen Sch√§tzungen.
""")

# Daten laden mit Fortschrittsanzeige
if 'data_loaded' not in st.session_state:
    st.session_state.data_loaded = False

if not st.session_state.data_loaded:
    with st.container():
        st.info("üöÄ Lade aktuelle Daten von NASA POWER API...")
        df = load_enhanced_data()
        st.session_state.df = df
        st.session_state.data_loaded = True
        st.success("‚úÖ Daten erfolgreich geladen!")
        st.rerun()
else:
    df = st.session_state.df

# Sidebar f√ºr Filter und Statistiken
st.sidebar.header("üîç Filter & Live-Daten Info")

# Datenquellen-Info
st.sidebar.subheader("üìä Datenquellen")
nasa_count = len(df[df['Datenquelle'] == 'NASA POWER API'])
geo_count = len(df[df['Datenquelle'] == 'Geographic Estimation'])

st.sidebar.metric("NASA POWER API", f"{nasa_count}", f"Live-Daten")
st.sidebar.metric("Geografische Sch√§tzung", f"{geo_count}", f"Fallback")

if nasa_count > 0:
    st.sidebar.success(f"‚úÖ {nasa_count} Standorte mit NASA-Daten")
if geo_count > 0:
    st.sidebar.info(f"üîÑ {geo_count} Standorte mit Sch√§tzungen")

# API Aktualisierung
st.sidebar.markdown("---")
if st.sidebar.button("üîÑ Daten aktualisieren", help="Neue API-Calls durchf√ºhren"):
    st.cache_data.clear()
    st.session_state.data_loaded = False
    st.rerun()

# Filter
dark_mode = st.sidebar.toggle("üåô Dark Mode", value=False)

bortle_filter = st.sidebar.slider(
    "Maximale Bortle-Skala",
    min_value=1,
    max_value=3,
    value=3
)

clear_nights_filter = st.sidebar.slider(
    "Mindestanzahl klare N√§chte pro Jahr",
    min_value=int(df['Klare_N√§chte_Jahr'].min()),
    max_value=int(df['Klare_N√§chte_Jahr'].max()),
    value=150
)

type_filter = st.sidebar.multiselect(
    "Standort-Typ",
    options=df['Typ'].unique(),
    default=df['Typ'].unique()
)

# Daten filtern
filtered_df = df[
    (df['Bortle_Skala'] <= bortle_filter) &
    (df['Klare_N√§chte_Jahr'] >= clear_nights_filter) &
    (df['Typ'].isin(type_filter))
]

# Karten-Style
if dark_mode:
    map_style = "carto-darkmatter"
    plot_template = "plotly_dark"
else:
    map_style = "open-street-map"
    plot_template = "plotly"

# Hauptbereich mit Tabs
tab1, tab2, tab3, tab4 = st.tabs(["üó∫Ô∏è Live Weltkarte", "üìä API Statistiken", "üìã Datenquellen", "üîÑ Daten-Management"])

with tab1:
    st.subheader("üåç Live-Daten Astrotourismus Weltkarte")
    
    # Weltkarte mit API-Status
    fig_map = px.scatter_mapbox(
        filtered_df,
        lat='Latitude',
        lon='Longitude',
        hover_name='Name',
        hover_data={
            'Land': True,
            'Bortle_Skala': True,
            'Klare_N√§chte_Jahr': True,
            'H√∂he_m': True,
            'Status': True,
            'Datenquelle': True,
            'Latitude': False,
            'Longitude': False
        },
        color='Klare_N√§chte_Jahr',
        color_continuous_scale='Viridis',
        size='Klare_N√§chte_Jahr',
        size_max=20,
        zoom=1,
        height=700,
        title=f"Live Astrotourismus-Daten ({len(filtered_df)} Standorte)"
    )
    
    fig_map.update_layout(
        mapbox_style=map_style,
        margin={"r":0,"t":50,"l":0,"b":0},
        template=plot_template
    )
    
    fig_map.update_coloraxes(
        colorbar_title="Klare N√§chte<br>pro Jahr"
    )
    
    st.plotly_chart(fig_map, use_container_width=True)
    
    # Live-Daten Legende
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("""
        **üì° Live-Daten Legende:**
        - üü¢ **NASA POWER API**: Echte 10-Jahres-Klimadaten
        - üü° **Geographic**: Sch√§tzung nach Geografie
        - üîµ **Punktgr√∂√üe**: Klare N√§chte pro Jahr
        - üé® **Farbe**: Klare N√§chte (gr√ºn = mehr)
        """)
    
    with col2:
        # Top 5 Standorte mit besten API-Daten
        nasa_sites = filtered_df[filtered_df['Datenquelle'] == 'NASA POWER API']
        if len(nasa_sites) > 0:
            top_nasa = nasa_sites.nlargest(5, 'Klare_N√§chte_Jahr')
            st.markdown("**üèÜ Top NASA-Daten Standorte:**")
            for _, site in top_nasa.iterrows():
                st.markdown(f"- **{site['Name']}**: {site['Klare_N√§chte_Jahr']} N√§chte ‚ú®")

with tab2:
    st.subheader("üìä API Datenqualit√§t & Statistiken")
    
    # Datenquellen-Vergleich
    col1, col2 = st.columns(2)
    
    with col1:
        # Datenquellen Verteilung
        fig_source = px.pie(
            df,
            names='Datenquelle',
            title='Datenquellen Verteilung',
            color_discrete_sequence=['#1f77b4', '#ff7f0e'],
            template=plot_template
        )
        st.plotly_chart(fig_source, use_container_width=True)
    
    with col2:
        # Vergleich NASA vs Geographic
        comparison_data = []
        for _, row in df.iterrows():
            comparison_data.append({
                'Name': row['Name'],
                'NASA_Wert': row['Klare_N√§chte_Jahr'] if row['Datenquelle'] == 'NASA POWER API' else None,
                'Geographic_Wert': row['Klare_N√§chte_Jahr'] if row['Datenquelle'] == 'Geographic Estimation' else None,
                'Datenquelle': row['Datenquelle']
            })
        
        comparison_df = pd.DataFrame(comparison_data)
        
        fig_comparison = px.scatter(
            filtered_df,
            x='H√∂he_m',
            y='Klare_N√§chte_Jahr',
            color='Datenquelle',
            size='Luftfeuchtigkeit_%',
            hover_data=['Name', 'Land'],
            title='H√∂he vs. Klare N√§chte (nach Datenquelle)',
            template=plot_template
        )
        st.plotly_chart(fig_comparison, use_container_width=True)
    
    # Detaillierte Statistiken
    st.subheader("üìà Detaillierte API-Statistiken")
    
    # Metriken
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        nasa_avg = df[df['Datenquelle'] == 'NASA POWER API']['Klare_N√§chte_Jahr'].mean()
        st.metric(
            "√ò NASA-Daten",
            f"{nasa_avg:.0f}" if not pd.isna(nasa_avg) else "N/A",
            "klare N√§chte"
        )
    
    with col2:
        geo_avg = df[df['Datenquelle'] == 'Geographic Estimation']['Klare_N√§chte_Jahr'].mean()
        st.metric(
            "√ò Geographic",
            f"{geo_avg:.0f}" if not pd.isna(geo_avg) else "N/A",
            "klare N√§chte"
        )
    
    with col3:
        max_clear = df['Klare_N√§chte_Jahr'].max()
        best_site = df.loc[df['Klare_N√§chte_Jahr'].idxmax(), 'Name']
        st.metric(
            "Beste Standort",
            best_site,
            f"{max_clear} N√§chte"
        )
    
    with col4:
        nasa_humidity = df[df['Datenquelle'] == 'NASA POWER API']['Luftfeuchtigkeit_%'].mean()
        st.metric(
            "√ò Luftfeuchtigkeit",
            f"{nasa_humidity:.1f}%" if not pd.isna(nasa_humidity) else "N/A",
            "NASA-Daten"
        )

with tab3:
    st.subheader("üìã Detaillierte Datenquellen & Methodik")
    
    # Suchfunktion
    search_term = st.text_input("üîç Standort suchen:", "")
    
    if search_term:
        mask = df['Name'].str.contains(search_term, case=False, na=False) | \
               df['Land'].str.contains(search_term, case=False, na=False)
        display_df = df[mask]
    else:
        display_df = df
    
    # Tabelle mit allen Details inklusive Datenquellen
    st.dataframe(
        display_df[['Name', 'Land', 'Klare_N√§chte_Jahr', 'Bortle_Skala', 
                   'H√∂he_m', 'Luftfeuchtigkeit_%', 'Datenquelle', 'Status']],
        use_container_width=True,
        hide_index=True,
        column_config={
            "Klare_N√§chte_Jahr": st.column_config.NumberColumn(
                "Klare N√§chte/Jahr",
                help="API-Daten oder geografische Sch√§tzung"
            ),
            "Datenquelle": st.column_config.TextColumn(
                "Datenquelle",
                help="NASA POWER API oder Geographic Estimation"
            ),
            "Status": st.column_config.TextColumn(
                "Status",
                help="‚úÖ Live Daten, üîÑ Sch√§tzung"
            )
        }
    )
    
    # Methodik-Erkl√§rung
    st.subheader("üî¨ Methodik & Datenqualit√§t")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        **üõ∞Ô∏è NASA POWER API:**
        - 10-Jahres Klimastatistiken (2010-2020)
        - Nachtbew√∂lkung < 30% = klare Nacht
        - Relative Luftfeuchtigkeit
        - Globale Abdeckung
        - Aktualisierung: t√§glich gecacht
        """)
    
    with col2:
        st.markdown("""
        **üåç Geografische Sch√§tzung:**
        - Basiert auf Breitengrad & H√∂he
        - Klimazonen-Ber√ºcksichtigung
        - Kontinentalit√§ts-Faktor
        - Fallback bei API-Fehlern
        - Konservative Sch√§tzungen
        """)
    
    # API-Status
    st.subheader("üîß API-Status & Performance")
    
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    st.info(f"üïê Letzte Aktualisierung: {current_time}")
    
    nasa_success_rate = len(df[df['Datenquelle'] == 'NASA POWER API']) / len(df) * 100
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("API Success Rate", f"{nasa_success_rate:.1f}%", "NASA POWER")
    
    with col2:
        cache_info = st.cache_data.get_stats()
        st.metric("Cache Hits", len(cache_info), "Optimierung")
    
    with col3:
        st.metric("Daten-Frische", "12h", "Auto-Update")

with tab4:
    st.subheader("üîÑ Daten-Management & Updates")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**üéõÔ∏è Cache Management:**")
        
        if st.button("üóëÔ∏è Cache leeren", help="Alle gecachten API-Daten l√∂schen"):
            st.cache_data.clear()
            st.success("‚úÖ Cache geleert! Daten werden bei n√§chster Anfrage neu geladen.")
        
        if st.button("üîÑ Neu laden", help="Daten komplett neu laden"):
            st.cache_data.clear()
            st.session_state.data_loaded = False
            st.rerun()
    
    with col2:
        st.markdown("**üìä Daten-Export:**")
        
        csv_data = df.to_csv(index=False)
        st.download_button(
            label="üíæ CSV Download",
            data=csv_data,
            file_name=f"astrotourismus_data_{datetime.now().strftime('%Y%m%d')}.csv",
            mime="text/csv"
        )
        
        json_data = df.to_json(orient='records', indent=2)
        st.download_button(
            label="üíæ JSON Download",
            data=json_data,
            file_name=f"astrotourismus_data_{datetime.now().strftime('%Y%m%d')}.json",
            mime="application/json"
        )
    
    # Update-Einstellungen
    st.markdown("**‚öôÔ∏è Update-Einstellungen:**")
    
    auto_update = st.checkbox("üîÑ Auto-Update aktivieren", value=True)
    if auto_update:
        update_interval = st.selectbox(
            "Update-Intervall:",
            ["6 Stunden", "12 Stunden", "24 Stunden"],
            index=1
        )
        st.info(f"‚ÑπÔ∏è Daten werden alle {update_interval} automatisch aktualisiert")
    
    # API-Limits Info
    st.markdown("**üì° API-Informationen:**")
    st.markdown("""
    - **NASA POWER**: Kostenlos, keine Limits
    - **Rate Limiting**: 0.1s Pause zwischen Calls
    - **Timeout**: 10 Sekunden pro Request
    - **Fallback**: Geografische Sch√§tzung bei Fehlern
    """)

# Seitenleiste Zusammenfassung
st.sidebar.markdown("---")
st.sidebar.subheader("üìä Live-Daten Zusammenfassung")

nasa_sites = len(df[df['Datenquelle'] == 'NASA POWER API'])
geo_sites = len(df) - nasa_sites

st.sidebar.markdown(f"""
**üõ∞Ô∏è NASA POWER API:** {nasa_sites} Standorte  
**üåç Geografische Sch√§tzung:** {geo_sites} Standorte  
**üìç Gesamt:** {len(df)} Regionen  

**üèÜ Beste Standorte (NASA-Daten):**
""")

# Top 3 NASA-Standorte
nasa_data = df[df['Datenquelle'] == 'NASA POWER API']
if len(nasa_data) > 0:
    top_3 = nasa_data.nlargest(3, 'Klare_N√§chte_Jahr')
    for i, (_, row) in enumerate(top_3.iterrows(), 1):
        st.sidebar.markdown(f"**{i}.** {row['Name']}: {row['Klare_N√§chte_Jahr']} N√§chte ‚≠ê")

st.sidebar.markdown("---")
st.sidebar.markdown("*üîÑ Daten automatisch alle 12h aktualisiert*")
